{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denizmsayin/singan/blob/master/run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPuukm-880dd",
        "colab_type": "code",
        "outputId": "4c838f18-c20f-45ba-c673-b29348634120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import subprocess as sp\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.5.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhurAwa4KyVJ",
        "colab_type": "text"
      },
      "source": [
        "## Notes\n",
        "- Every generator and critic at every scale has the same architecture, with 5 Conv(3x3)-BN-LReLU layers.\n",
        "- The patch size is given as 11x11, which comes from the receptive field of the 5 layer deep network.\n",
        "- How the number of kernels change is not exactly clear, paper says \"start with 32, double once every 4 scales\"\n",
        "- It is not clear whether the conv layers use padding (zero, reflect?) to preserve size or not. We assume for now that the generators do preserve the size, but it does not seem necessary for the critics.\n",
        "- How the downsampling is done is not clear from the paper. We assume bicubic interpolation.\n",
        "- For the coarsest scale, authors say that \"the effective receptive field at this level is typically∼1/2of the image’s height\". ~~We assume that this means the input size at the coarsest scale is somewhere between 20 and 25 pixels.~~ The authors later state that they use 25 px for the coarsest and 250 pixels for the finest scale along with a rescaling ratio of 4/3. \n",
        "- Lots of training details are given in the supplementary material.\n",
        "- It is not clear "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y9niqk59UT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_bsds300():\n",
        "  if os.path.isdir('BSDS300'):\n",
        "    print('Dataset already downloaded')\n",
        "  else:\n",
        "    sp.call(('wget', 'https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz'))\n",
        "    sp.call(('tar', '-xvzf', 'BSDS300-images.tgz'))\n",
        "    sp.call(('rm', '-f', 'BSDS300-images.tgz'))\n",
        "    print('Downloaded dataset successfully')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0tqLF1cXOmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv2DBlock(nn.Module):\n",
        "  \"\"\" Combine Conv2d-BN-LReLU into a single block \"\"\"\n",
        "  # the 0.2 negative slope is given in the supplementary materials\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, activation, conv_kwargs={}, bn_kwargs={}):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, **conv_kwargs)\n",
        "    self.bn = nn.BatchNorm2d(out_channels, **bn_kwargs)\n",
        "    self.activ = activation\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.activ(self.bn(self.conv(x)))\n",
        "\n",
        "class SGNet(nn.Module):\n",
        "  def __init__(self, output_channels=3, kernel_count=32, final_activation=nn.Tanh(), final_bn=False, num_blocks=5):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList()\n",
        "    self.layers.append(nn.ZeroPad2d(num_blocks)) # initial padding, as explained in the SM\n",
        "    in_channels = 3\n",
        "    for _ in range(num_blocks-1): # multiple Conv2D blocks with LeakyReLU\n",
        "      self.layers.append(Conv2DBlock(in_channels, kernel_count, 3, nn.LeakyReLU(negative_slope=0.2)))\n",
        "      in_channels = kernel_count\n",
        "    # the final activation depends on whether this is the generator or critic\n",
        "    if final_bn:\n",
        "      self.layers.append(Conv2DBlock(kernel_count, output_channels, 3, final_activation))\n",
        "    else:\n",
        "      self.layers.append(nn.Conv2d(kernel_count, output_channels, 3))\n",
        "      self.layers.append(final_activation)\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "class Mean(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.mean(x)\n",
        "\n",
        "# [gen1] -> View, crit1 = View + crit1\n",
        "# [gen1, gen2] -> View, crit2 = View + crit2\n",
        "# ...\n",
        "\n",
        "def sample_noise_like(ref_img, device='cpu'):\n",
        "  return torch.from_numpy(np.random.uniform(-1, 1, size=ref_img.shape).astype(ref_img.dtype)).to(device)\n",
        "\n",
        "class MultiScaleSGNetView(nn.Module):\n",
        "  def __init__(self, scales, scaling_factor, noise_sampler):\n",
        "    # scales = [gen1, gen2 ...]\n",
        "    self.scales = scales\n",
        "    self.noise_sampler = noise_sampler\n",
        "    self.scaling_factor = scaling_factor # e.g. 4/3\n",
        "    for g in self.scales[:-1]:\n",
        "      g.requires_grad_(False)\n",
        "\n",
        "  def forward(self, x, z_input=None):\n",
        "    \"\"\"\n",
        "    z_input: either None (noise is generated automatically), \n",
        "             a single tensor (used as input to the coarsest scale)\n",
        "             or a list of tensors (used as input to each scale in asc. order)\n",
        "    \"\"\"\n",
        "    for i, g in enumerate(self.scales):\n",
        "      if z_input is None:\n",
        "        z = self.noise_sampler(x)\n",
        "      elif type(z_input) is list:\n",
        "        z = z_input[i]\n",
        "      else:\n",
        "        z, z_input = z_input, None\n",
        "      x_gen = g(x, z)\n",
        "      x = F.interpolate(x_gen, scaling_factor=self.scaling_factor, mode='nearest')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UpI7xyUYJoo",
        "colab_type": "code",
        "outputId": "72bdb752-53f1-4faa-b465-96b33cfb95b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "prepare_bsds300()\n",
        "\n",
        "DS_DIR = 'BSDS300/images/train'\n",
        "EXAMPLE_IDX = 11\n",
        "IMG_LIST = sorted(os.listdir(DS_DIR))\n",
        "EXAMPLE_IMG_PATH = os.path.join(DS_DIR, IMG_LIST[EXAMPLE_IDX])\n",
        "\n",
        "orig_img_uint = np.array(Image.open(EXAMPLE_IMG_PATH).resize((25, 25), Image.BICUBIC))\n",
        "plt.imshow(orig_img_uint)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset already downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd6f12fc780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQbM5wSAgu8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# as given in the paper (LR decrease not implemented)\n",
        "LEARNING_RATE = 0.0005\n",
        "BETA_1 = 0.5\n",
        "BETA_2 = 0.999\n",
        "NUM_ITERS = 2000\n",
        "LR_DROP_STEP = 1600\n",
        "LR_DROP_MULT = 0.1\n",
        "GEN_STEP_PER_ITER = 3\n",
        "DIS_STEP_PER_ITER = 3\n",
        "REC_ALPHA = 10.0\n",
        "GP_WEIGHT = 0.1\n",
        "\n",
        "PRINT_EVERY = 50\n",
        "DEVICE = 'cuda'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cDWoeR6fQtS",
        "colab_type": "code",
        "outputId": "5e5bfe51-de4f-4d3b-cee4-fea695c9d47b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "def img2net(img_uint):\n",
        "  # convert [0, 255] uint8 (H, W, C) to [-1, 1] float32 (1, C, H, W)\n",
        "  rescaled = (img_uint.astype('float32') / 127.5) - 1.0\n",
        "  chw = np.transpose(rescaled, (2, 0, 1))\n",
        "  return torch.from_numpy(np.expand_dims(chw, axis=0)).to(DEVICE)\n",
        "\n",
        "def net2img(img_float):\n",
        "  chw = np.squeeze(img_float.detach().cpu().numpy())\n",
        "  hwc = np.transpose(chw, (1, 2, 0))\n",
        "  return ((hwc + 1.0) * 127.5).astype('uint8')\n",
        "\n",
        "generator = SGNet(output_channels=3, kernel_count=32, final_activation=nn.Tanh()).to(DEVICE)\n",
        "patch_critic = SGNet(output_channels=1, kernel_count=32, final_activation=nn.Identity()).to(DEVICE)\n",
        "critic = torch.nn.Sequential(patch_critic, Mean()).to(DEVICE)\n",
        "print(generator)\n",
        "print(critic)\n",
        "\n",
        "gen_optimizer = torch.optim.Adam(generator.parameters(), LEARNING_RATE, (BETA_1, BETA_2))\n",
        "dis_optimizer = torch.optim.Adam(critic.parameters(), LEARNING_RATE, (BETA_1, BETA_2))\n",
        "\n",
        "gen_sched = torch.optim.lr_scheduler.StepLR(gen_optimizer, LR_DROP_STEP, LR_DROP_MULT)\n",
        "dis_sched = torch.optim.lr_scheduler.StepLR(dis_optimizer, LR_DROP_STEP, LR_DROP_MULT)\n",
        "\n",
        "orig_img = img2net(orig_img_uint)\n",
        "print(orig_img.shape)\n",
        "\n",
        "def sample_noise(): # check this\n",
        "  return torch.from_numpy(np.random.uniform(-1, 1, size=orig_img.shape).astype('float32')).to(DEVICE)\n",
        "  \n",
        "z_rec = sample_noise()\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "for step in range(NUM_ITERS):\n",
        "\n",
        "  # real 1, fake 0\n",
        "\n",
        "  for _ in range(GEN_STEP_PER_ITER):\n",
        "    gen_optimizer.zero_grad()\n",
        "\n",
        "    z = sample_noise()\n",
        "    fake_img = generator(z)\n",
        "\n",
        "    # adversarial loss\n",
        "    adv_loss = -critic(fake_img)\n",
        "\n",
        "    # reconstruction loss\n",
        "    rec_img = generator(z_rec)\n",
        "    # the representation space of the images is not clear in the paper.\n",
        "    # since the reconstruction loss seemed very low to us in the [-1, 1]\n",
        "    # range, we decided to calculate it in the [0, 255] range instead\n",
        "    # EDIT: after checking out their own code, it seems that there is\n",
        "    # no multiplier. however, the reconstruction loss remains too small?\n",
        "    rec_loss = mse(orig_img, rec_img)\n",
        "\n",
        "    gen_loss = adv_loss + REC_ALPHA * rec_loss\n",
        "    gen_loss.backward()\n",
        "    gen_optimizer.step()\n",
        "    gen_sched.step()\n",
        "\n",
        "  for _ in range(DIS_STEP_PER_ITER):\n",
        "    dis_optimizer.zero_grad()\n",
        "\n",
        "    zc = sample_noise()\n",
        "    fake_imgc = generator(zc)\n",
        "    epsilon = np.random.uniform(0, 1)\n",
        "\n",
        "    # adversarial loss\n",
        "    # take a sample from the line between the real and generated images\n",
        "    # for use in the gradient penalty (Impr. Training of WGANs)\n",
        "    grad_sample = epsilon * orig_img + (1 - epsilon) * fake_imgc\n",
        "    f_grad_sample = critic(grad_sample)\n",
        "    grad, = torch.autograd.grad(f_grad_sample, grad_sample, create_graph=True, retain_graph=True)\n",
        "    grad_loss = (torch.norm(grad) - 1)**2\n",
        "\n",
        "    fake_loss = critic(fake_imgc)\n",
        "    real_loss = -critic(orig_img)\n",
        "    adv_loss =  fake_loss + real_loss + GP_WEIGHT * grad_loss\n",
        "    adv_loss.backward()\n",
        "    dis_optimizer.step()\n",
        "    dis_sched.step()\n",
        "\n",
        "  if step % PRINT_EVERY == 0:\n",
        "    print('Step: {}'.format(step))\n",
        "    print('Generator adv: {:.3f}, rec: {:.3f}'.format(adv_loss.data, rec_loss.data))\n",
        "    print('Critic fake: {:.3f} real: {:.3f} grad: {:.3f}'.format(fake_loss.data, real_loss.data, grad_loss.data))\n",
        "    if step != 0:\n",
        "      elapsed = time() - last_print\n",
        "      print('Steps per second: {:.2f}'.format(PRINT_EVERY / elapsed))\n",
        "    plt.imshow(net2img(fake_img))\n",
        "    plt.show()\n",
        "    last_print = time()\n",
        "\n",
        "plt.imshow(net2img(generator(z_rec)))\n",
        "plt.show()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SGNet(\n",
            "  (layers): ModuleList(\n",
            "    (0): ZeroPad2d(padding=(5, 5, 5, 5), value=0.0)\n",
            "    (1): Conv2DBlock(\n",
            "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activ): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (2): Conv2DBlock(\n",
            "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activ): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (3): Conv2DBlock(\n",
            "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activ): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (4): Conv2DBlock(\n",
            "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activ): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (5): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (6): Tanh()\n",
            "  )\n",
            ")\n",
            "Sequential(\n",
            "  (0): SGNet(\n",
            "    (layers): ModuleList(\n",
            "      (0): ZeroPad2d(padding=(5, 5, 5, 5), value=0.0)\n",
            "      (1): Conv2DBlock(\n",
            "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activ): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "      (2): Conv2DBlock(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activ): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "      (3): Conv2DBlock(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activ): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "      (4): Conv2DBlock(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activ): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "      (5): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (6): Identity()\n",
            "    )\n",
            "  )\n",
            "  (1): Mean()\n",
            ")\n",
            "torch.Size([1, 3, 25, 25])\n",
            "Step: 0\n",
            "Generator adv: -0.031, rec: 0.196\n",
            "Critic fake: -0.162 real: 0.042 grad: 0.891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-70e5175b9d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mreal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0madv_loss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfake_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGP_WEIGHT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0madv_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mdis_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mdis_sched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}